{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4_S8_backbone.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPU70JwakdtFBHy3Qo1B0T3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimbsg/EVA4_S8/blob/master/EVA4_S8_backbone_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUM9hpi6n2yT",
        "colab_type": "text"
      },
      "source": [
        "Manual created model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXaIlEAJRvMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "drop_out = 0.05\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):    \n",
        "    super(Net, self).__init__()\n",
        "    \n",
        "    # Maxpooling\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "    # Input block\n",
        "    self.conv1 = nn.Sequential(nn.Conv2d(3,16,3,1,1), nn.BatchNorm2d(16),nn.ReLU(), nn.Dropout(p=drop_out),\n",
        "                                nn.Conv2d(16,32,3,1,1, dilation=1), nn.ReLU(), nn.BatchNorm2d(32),nn.Dropout(p=drop_out)\n",
        "    )\n",
        "    # Convolution block        \n",
        "    self.conv2 = nn.Sequential(nn.Conv2d(32,64,3,1,1), nn.BatchNorm2d(64),nn.ReLU(), nn.Dropout(p=drop_out),\n",
        "                                nn.Conv2d(64,128,3,1,1,dilation=2), nn.BatchNorm2d(128),nn.ReLU(),nn.Dropout(p=drop_out)\n",
        "    )\n",
        "    # Transition block\n",
        "    self.convblock1 = nn.Sequential(nn.Conv2d(128,64,1), nn.BatchNorm2d(64), nn.ReLU())\n",
        "    \n",
        "    # Convolution block\n",
        "    self.conv3 = nn.Sequential(nn.Conv2d(64,128,3,1,1), nn.BatchNorm2d(128),nn.ReLU(), nn.Dropout(p=drop_out),\n",
        "                                nn.Conv2d(128,256,3,1,1), nn.BatchNorm2d(256),nn.ReLU(), nn.Dropout(p=drop_out)\n",
        "    )        \n",
        "    # Transition block\n",
        "    self.convblock2 = nn.Sequential(nn.Conv2d(256,64,1), nn.BatchNorm2d(64), nn.ReLU())  \n",
        "    \n",
        "    # Convolution block      \n",
        "    self.conv4 = nn.Sequential(nn.Conv2d(64,128,3,1,1, dilation = 1), nn.BatchNorm2d(128),nn.ReLU(), nn.Dropout(p=drop_out)\n",
        "    )\n",
        "    # Transition block\n",
        "    # self.convblock3 = nn.Sequential(nn.Conv2d(128,32,3,1,1), nn.ReLU(), nn.BatchNorm2d(32))\n",
        "    \n",
        "    # Depthwise block\n",
        "    self.dwconv = nn.Sequential(nn.Conv2d(128,128,3,padding=1,groups=128), \n",
        "    nn.Conv2d(128,256,1),nn.BatchNorm2d(256), nn.Dropout(p=drop_out), nn.ReLU()\n",
        "    )\n",
        "    # Output classes block\n",
        "    # self.convblock4 = nn.Sequential(nn.Conv2d(128,10,1), nn.ReLU(), nn.BatchNorm2d(10))\n",
        "    self.convblock3 = nn.Sequential(nn.Conv2d(256,10,1), nn.BatchNorm2d(10), nn.ReLU())\n",
        "\n",
        "    # GAP block\n",
        "    self.gap = nn.AvgPool2d(kernel_size = 3)\n",
        "\n",
        "  def forward(self, x):    \n",
        "    x = self.pool(self.conv1(x))\n",
        "    # print(\"1\")\n",
        "    # print(x.shape)\n",
        "    x = self.convblock1(self.pool(self.conv2(x)))        \n",
        "    # print(\"2\")\n",
        "    # print(x.shape)\n",
        "    x = self.convblock2(self.pool(self.conv3(x)))\n",
        "    # print(\"3\")\n",
        "    # print(x.shape)\n",
        "    # x = self.conv4(x)        \n",
        "    # x = self.convblock3(x)\n",
        "    # x = self.pool(x)\n",
        "    x = self.convblock3(self.dwconv(self.conv4(x)))\n",
        "    # print(\"4\")\n",
        "    # print(x.shape)\n",
        "    x = self.gap(x)\n",
        "    \n",
        "    x = x.view(-1, 10*1*1)\n",
        "    return F.log_softmax(x, dim=-1)\n",
        "\n",
        "net = Net()        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X-MwOp8S6t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device,trainloader,optimizer,criterion,epoch):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "        print('[%d, %5d] loss: %.3f' %\n",
        "              (epoch + 1, i + 1, running_loss / 2000))\n",
        "        running_loss = 0.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R4D1INnTfsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_acc(testloader,net,device):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %2f %%' % (\n",
        "      100 * correct / total))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw3C-Sj6UFyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def class_acc(testloader,net,device,classes):\n",
        "  class_correct = list(0. for i in range(10))\n",
        "  class_total = list(0. for i in range(10))\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          c = (predicted == labels).squeeze()\n",
        "          for i in range(4):\n",
        "              label = labels[i]\n",
        "              class_correct[label] += c[i].item()\n",
        "              class_total[label] += 1\n",
        "\n",
        "  for i in range(10):\n",
        "      print('Accuracy of %5s : %2d %%' % (\n",
        "          classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICmyo-oP2PZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_ckp(state, checkpoint_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK2rEasE2TAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into       \n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_loss_min = checkpoint['valid_loss_min']\n",
        "    # return model, optimizer, epoch value, min validation loss \n",
        "    return model, optimizer, checkpoint['epoch'], valid_loss_min"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}